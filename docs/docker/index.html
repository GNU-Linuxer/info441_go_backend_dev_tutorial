<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta http-equiv="X-UA-Compatible" content="ie=edge"><link rel="stylesheet" href="../lib/bulma.min.css"><link rel="stylesheet" href="../lib/font-awesome-4.7.0/css/font-awesome.min.css"><link rel="stylesheet" href="../lib/prism.css"><link rel="icon" href="../img/page-icon.png"><meta property="og:type" content="website"><meta property="og:site_name" content="INFO Tutorials"><meta property="og:title" content="Containerizing with Docker"><meta property="og:description" content="Using software containers for development, testing, and deployment"><meta property="og:image" content="https://drstearns.github.io/tutorials/img/page-icon.png"><title>Containerizing with Docker</title><style>.is-funky{background-image:linear-gradient(to right,#006064,#880E4F)}.is-funky .subtitle,.is-funky .title{color:#fff}.bookmark-link{color:#ddd;margin-left:.25em}.home-link{color:#eee}.home-link:hover{color:#fff}.byline{font-size:.85rem;font-style:italic}</style></head><body><header><div class="hero is-funky"><div class="hero-body"><div class="container"><div class="columns is-mobile"><div class="column"><h1 class="title">Containerizing with Docker</h1><p class="subtitle">Using software containers for development, testing, and deployment</p></div><div class="column is-narrow"><a href=".." class="home-link"><span class="icon is-medium"><i class="fa fa-home" aria-hidden="true" aria-label="back to table of contents"></i></span></a></div></div></div></div></div></header><main class="section"><div class="container"><div class="content"><p class="byline">Last edited on Jul 28, 2017 by <a href="https://ischool.uw.edu/people/faculty/dlsinfo">Dave Stearns</a></p><p>To deploy a web server, you need to get your application on to a computer that is connected to the Internet with a stable IP address. In the bad old days of the Web, this was done by renting rack space in a data center and installing your own gear. Since you were buying your own computers, you had to guess how much computing power, memory, and disk storage you might need. If you got it wrong, your computers would either sit idle most of the time, or struggle to keep up with the load. And even if you got it right, you had to buy enough equipment to handle your peak load, even if that occurred for only a few minutes each day.</p><p>Starting in the 2000s, several hosting companies developed more flexible alternatives based on <strong>virtual machines (VMs)</strong>. One physical machine could host several VMs, sharing its CPU, memory, storage, and I/O devices via a <a href="https://en.wikipedia.org/wiki/Hypervisor">hypervisor</a>. A virtual machine is like a computer running within another computer. To the developer, each VM felt like a real independent computer; it had a full copy of the operating system, application software, and any other supporting files your server needed, and it was isolated from the other VMs running on the same physical machine. But since they were virtual, you could spin-up a new VM within a few minutes, and spin it back down again when it was no longer needed. New VMs could be allocated to any physical machine, so hosting companies were able to more fully utilize their hardware.</p><p>As desktop and laptop machines became more powerful, developers realized they could use this same technique to create consistent, isolated development environments on their own computers. Tools like <a href="https://www.vagrantup.com/">Vagrant</a> made it easy for every developer on the team to spin-up the same Linux VM, with the same compiler and database versions, regardless of which host OS they happened to use. VMs also made it easy to work on multiple projects with conflicting dependencies, as the VMs provided separate isolated environments: if one project required version 1 of some server, but another required version 2, you could easily switch between them by spinning down one VM and spinning up another. And since the developers were now working in the same environment as their target production servers, there were less unexpected failures when rolling out new versions.</p><p>This all worked well, but there were a lot of inefficiencies. VMs are quite heavy-weight: each VM includes a full copy of the entire operating system (OS), so the OS is duplicated in memory for each VM, even if all the VMs use the same OS. Spinning up a VM also requires a full operating system startup sequence, which can take a few minutes.</p><p>During the 2000s, several features were added to the Linux kernel that provided similar levels of isolation for multiple <em>applications</em> running on the <em>same operating system</em>. These features enable multiple isolated "containers" within a single OS, each of which has a separate file system, process group, and network stack, just like a VM. But unlike VMs, these containers share the underlying OS, so they have a much smaller memory footprint, and can start/stop almost instantly.</p><p>These new kernel features were complex and difficult to use, so in 2013 a new company named Docker released a set of command-line tools that made it easier to build, run, and manage these containers. Docker became very popular, very quickly, and is now commonly used not only for deployment, but also for running any sort of server software on a development machine.</p><h2 id="secwhatisdocker">What is Docker?</h2><p>At its core, Docker is a technology for running application software in isolated, secure, and reusable containers. A container is like a VM, but much lighter-weight, as it can share the underlying operating system (OS), known as the <strong>host OS</strong>.</p><p><img src="img/container-vs-vm.png" alt="visual comparison of VMs and containers"></p><p>Docker containers are isolated from each other, as well as the host OS. Each container has its own independent file system, so it can't access the host's file system unless you explicitly allow it to do so (see the <a href="#secmountingvolumes">Mounting Volumes</a> section below). Each container also has its own independent network address and stack by default, and only the ports you want accessible will be published to the host OS. The process groups are also separate and isolated so that a process in one container can't see or communicate with processes in other containers, or the host OS.</p><p>All of this isolation is good for not only handling conflicting dependencies, but also security. If a web application gets compromised, the attacker is trapped inside the container and can't do any real damage to the host OS or other containers. Any changes the attacker makes within a running container have no effect other containers started from the same image, and are erased when the current container is removed.</p><p>Docker consists of a set of command-line tools and a <a href="https://en.wikipedia.org/wiki/Daemon_(computing)">daemon process</a> that runs on Linux (version 3.10 and beyond) or Windows Server (version 2016 and beyond). The tools just provide a command-line interface (CLI) to the daemon process, so all the real work happens in the daemon.</p><p>Since the daemon process requires Linux or Windows Server, using Docker on your Mac or Windows Professional development machine requires a Linux VM. In the early days of Docker you had to install this yourself, but now their native applications for Mac and Windows come with a minimal Linux VM that runs on the native hypervisor built into MacOS and Windows Pro. The command line interface (CLI) still runs on the host operating system but communicates with the daemon process running within the Linux VM.</p><p><img src="img/dev-machine.png" alt="stack on development machine"></p><h2 id="seccontainerimages">Container Images</h2><p>In addition to leveraging the underlying operating system's containerization features, Docker also defines a format for container images. A container image is like a black box that encapsulates all the software and files your application needs to run into one easily-managed unit. Container images can be uploaded to Docker's central container registry, known as <a href="https://hub.docker.com/">Docker Hub</a>, which is like GitHub but for Docker container images instead of git repos. Docker Hub already contains container images for all the popular open-source server software, and you can create your own account to host your own container images.</p><h2 id="secinstallingdocker">Installing Docker</h2><h2 id="secrunningcontainers">Running Containers</h2><h3 id="secrunningdetachedcontainers">Running Detached Containers</h3><h3 id="secpublishingports">Publishing Ports</h3><h3 id="secmountingvolumes">Mounting Volumes</h3><h3 id="secsettingenvironmentvariables">Setting Environment Variables</h3><h2 id="secbuildingcontainers">Building Containers</h2><h2 id="secdeployingcontainers">Deploying Containers</h2></div></div></main><footer class="footer"><div class="container"><div class="content"><p>Created by <a href="https://ischool.uw.edu/people/faculty/dlsinfo">Dave Stearns</a>, <a href="https://ischool.uw.edu">The Information School</a>, <a href="https://uw.edu">University of Washington</a></p><p><a href=".."><span class="icon"><i class="fa fa-home"></i> </span>back to contents</a></p></div></div></footer><script>var headings=document.querySelectorAll("h2,h3,h4,h5");headings.forEach(function(e){var a=document.createElement("a");a.textContent="#",a.href="#"+e.id,a.classList.add("bookmark-link"),e.appendChild(a)})</script><script>!function(e,t,a,n,c,o,s){e.GoogleAnalyticsObject=c,e[c]=e[c]||function(){(e[c].q=e[c].q||[]).push(arguments)},e[c].l=1*new Date,o=t.createElement(a),s=t.getElementsByTagName(a)[0],o.async=1,o.src="https://www.google-analytics.com/analytics.js",s.parentNode.insertBefore(o,s)}(window,document,"script",0,"ga"),ga("create","UA-102177301-1","auto"),ga("send","pageview")</script></body></html>